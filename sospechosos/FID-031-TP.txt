Facial Expression Recognition (FER) is employed in various domains such as education, gaming, robotics, healthcare, and more. For instance, facial expression techniques enable an interactive robot with Artificial Intelligence to recognize human faces, detect the emotions of the person it is interacting with, and then use these emotions to choose appropriate responses. One application for face emotion detection is playing music based on the user’s mood. By analyzing the user’s facial expression, we can infer their feelings. Consequently, new emotion models require further investigation, as existing ones struggle to accurately measure music's connection with facial emotion. In this paper, we implement this task using a Convolution Neural Network (CNN) based deep learning approach. Deep learning can analyze unstructured data, videos, and other media forms more effectively than traditional machine learning. In our study, we have developed a real-time system that can recognize human faces, assess human emotions, and even recommend music to users. The OAHEGA and FER-2013 datasets were used for experimental study. We developed and trained two emotion recognition models using various combinations of these datasets. The proposed model achieves an accuracy of 73.02%. Our CNN model can predict six emotions: anger, fear, joy, neutral, sadness, and surprise. The proposed system can be applied in various settings where real-time facial recognition is essential.